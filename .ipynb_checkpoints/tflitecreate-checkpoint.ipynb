{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b070ab53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ________________________post training quantization__________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e0dcb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heman\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "059848d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# without quantization\n",
    "convertor = tf.lite.TFLiteConverter.from_saved_model(\"../leaf disease prediction/Models/1\")\n",
    "tf_lite_model = convertor.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f03f9dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "743904"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf_lite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a540dd7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b85a2b66",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13380\\3116070423.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# with quantization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mconvertor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTFLiteConverter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_saved_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../leaf disease prediction/Models/1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mconvertor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOptimize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDEFAULT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtf_model1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvertor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# with quantization\n",
    "convertor = tf.lite.TFLiteConverter.from_saved_model(\"../leaf disease prediction/Models/1\")\n",
    "convertor.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tf_model1 = convertor.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e16c9c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201096"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "032b1e02",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf_model1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13380\\140400643.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"quantize_tflite_model.tflite\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf_model1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tf_model1' is not defined"
     ]
    }
   ],
   "source": [
    "with open(\"quantize_tflite_model.tflite\",\"wb\") as f:\n",
    "    f.write(tf_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8375d52-6a08-4b82-9daa-ef9b33624c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f802daf4-537e-490f-b211-0cee8906e070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating labels\n",
    "def recreate_labels():\n",
    "  # 1) We use this in order to ignore any hidden files that might be here.\n",
    "  # 'Datasets' is the name of the folder where we store our training data. The 'listdir' is used to fetch all the folder names.\n",
    "  labels = [folder for folder in os.listdir('PlantVillage/Plant') if not folder.startswith('.')]\n",
    "  \n",
    "  # 2) Then, we output the contents of each folder name to a file.\n",
    "  with open('labels.txt', 'w') as file:\n",
    "    for label in labels:\n",
    "      file.write(label)\n",
    "      file.write('\\n')\n",
    "\n",
    "recreate_labels()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaff2fa-4ccb-4823-9b69-304fc89aafe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2c203ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"../leaf disease prediction/Models/quantize_aware_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8c2700f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9416 files belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"PlantVillage/Plant\",\n",
    "    shuffle = True,\n",
    "    image_size = (256,256),\n",
    "    batch_size = 50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a682520f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_partition_and_data_tuning(ds,train_split= 0.8 ,val_split=0.1,test_split = 0.1 ,shuffle = True,shuffle_size = 10000):\n",
    "    train_size = int(len(dataset)*train_split)\n",
    "    val_size = int(len(dataset)*val_split)\n",
    "    test_size = int(len(dataset)*test_split)\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(shuffle_size,seed = 12) \n",
    "    train_data = ds.take(train_size)\n",
    "    remain_data = ds.skip(train_size)\n",
    "    val_data = remain_data.take(val_size)\n",
    "    test_data = remain_data.skip(val_size)\n",
    "    train_data = train_data.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    val_data = val_data.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    test_data = test_data.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return train_data,val_data,test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b55c119",
   "metadata": {},
   "outputs": [],
   "source": [
    "train,val,test = get_partition_and_data_tuning(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9b3a0773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def representative_dataset_gen():\n",
    "    # Provide sample representative input data\n",
    "    for _ in range(100):\n",
    "        sample_data = np.random.rand(1, 256, 256, 3)\n",
    "        yield [sample_data.astype(np.float32)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "88f644b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6e46f644",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 24). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\heman\\AppData\\Local\\Temp\\tmptd9qd5_j\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\heman\\AppData\\Local\\Temp\\tmptd9qd5_j\\assets\n",
      "C:\\Users\\heman\\anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:766: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16204\\976399796.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mquantized_tflite_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    928\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m     \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 930\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_and_export_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    931\u001b[0m     \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\u001b[0m in \u001b[0;36m_convert_and_export_metrics\u001b[1;34m(self, convert_func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    906\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_conversion_params_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 908\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    909\u001b[0m     \u001b[0melapsed_time_ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1337\u001b[0m         \u001b[0mInvalid\u001b[0m \u001b[0mquantization\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1338\u001b[0m     \"\"\"\n\u001b[1;32m-> 1339\u001b[1;33m     \u001b[0msaved_model_convert_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_as_saved_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1340\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msaved_model_convert_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1341\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0msaved_model_convert_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\u001b[0m in \u001b[0;36m_convert_as_saved_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1319\u001b[0m           self._convert_keras_to_saved_model(temp_dir))\n\u001b[0;32m   1320\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model_dir\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1321\u001b[1;33m         return super(TFLiteKerasModelConverterV2,\n\u001b[0m\u001b[0;32m   1322\u001b[0m                      self).convert(graph_def, input_tensors, output_tensors)\n\u001b[0;32m   1323\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(self, graph_def, input_tensors, output_tensors)\u001b[0m\n\u001b[0;32m   1136\u001b[0m         **converter_kwargs)\n\u001b[0;32m   1137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1138\u001b[1;33m     return self._optimize_tflite_model(\n\u001b[0m\u001b[0;32m   1139\u001b[0m         result, self._quant_mode, quant_io=self.experimental_new_quantizer)\n\u001b[0;32m   1140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\convert_phase.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mConverterError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mconverter_error\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mconverter_error\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\u001b[0m in \u001b[0;36m_optimize_tflite_model\u001b[1;34m(self, model, quant_mode, quant_io)\u001b[0m\n\u001b[0;32m    866\u001b[0m         \u001b[0mq_bias_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquant_mode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m         \u001b[0mq_allow_float\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquant_mode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_allow_float\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 868\u001b[1;33m         model = self._quantize(model, q_in_type, q_out_type, q_activations_type,\n\u001b[0m\u001b[0;32m    869\u001b[0m                                q_bias_type, q_allow_float)\n\u001b[0;32m    870\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\u001b[0m in \u001b[0;36m_quantize\u001b[1;34m(self, result, input_type, output_type, activations_type, bias_type, allow_float)\u001b[0m\n\u001b[0;32m    610\u001b[0m                                                 custom_op_registerers_by_func)\n\u001b[0;32m    611\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_calibrate_only\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_new_quantizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m       calibrated = calibrate_quantize.calibrate(\n\u001b[0m\u001b[0;32m    613\u001b[0m           self.representative_dataset.input_gen)\n\u001b[0;32m    614\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\convert_phase.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mConverterError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mconverter_error\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mconverter_error\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\optimize\\calibrator.py\u001b[0m in \u001b[0;36mcalibrate\u001b[1;34m(self, dataset_gen)\u001b[0m\n\u001b[0;32m    224\u001b[0m       \u001b[0mdataset_gen\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0mgenerator\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mgenerates\u001b[0m \u001b[0mcalibration\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m     \"\"\"\n\u001b[1;32m--> 226\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_gen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresize_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_calibrator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCalibrate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\optimize\\calibrator.py\u001b[0m in \u001b[0;36m_feed_tensors\u001b[1;34m(self, dataset_gen, resize_input)\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_calibrator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFeedTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msignature_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_calibrator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFeedTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m   @convert_phase(Component.OPTIMIZE_TFLITE_MODEL,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "quantized_tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cced58f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('quantized_model.tflite', 'wb') as f:\n",
    "    f.write(quantized_tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c8dedfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _________________--testing the quantize_aware_model_________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e42c9f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=\"quantize_tflite_model.tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea0b2521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: [ 50 256 256   3]\n",
      "Input size: <class 'numpy.float32'>\n",
      "output shape: [50 10]\n",
      "output size: <class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(\"Input shape:\",input_details[0]['shape'])\n",
    "print(\"Input size:\",input_details[0]['dtype'])\n",
    "print(\"output shape:\",output_details[0]['shape'])\n",
    "print(\"output size:\",output_details[0]['dtype'])\n",
    "interpreter.resize_tensor_input(input_details[0][\"index\"],(1,256,256,3))\n",
    "interpreter.resize_tensor_input(output_details[0][\"index\"],(1,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474aa742",
   "metadata": {},
   "source": [
    "Resize Tensor shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "de73e72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "867d9843",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images_batch,labels_batch in test.take(1):\n",
    "    first_img =np.array(images_batch,dtype=\"float32\")\n",
    "#     print(first_img)\n",
    "    first_label = labels_batch.numpy()\n",
    "    interpreter.allocate_tensors()\n",
    "#     print(\"first image to predict\")\n",
    "#     plt.imshow(first_img)\n",
    "#     print(\"actual label:\",dataset.class_names[first_label])\n",
    "    interpreter.set_tensor(input_details[0]['index'],first_img)\n",
    "    interpreter.invoke()\n",
    "    batch_prediction=interpreter.get_tensor(output_details[0]['index'])\n",
    "    label1 = np.argmax(batch_prediction)\n",
    "#     print(\"predicted label:\",dataset.class_names[label1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "76e56b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "db3d5529",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,50):\n",
    "    arr.append( np.argmax(batch_prediction[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "aaefdfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 5, 8, 6, 3, 4, 9, 4, 0, 8, 4, 8, 4, 6, 5, 9, 1, 6, 4, 9, 3, 0, 3, 3, 4, 6, 4, 6, 4, 1, 1, 5, 8, 7, 6, 1, 8, 6, 4, 3, 6, 5, 9, 5, 1, 4, 6, 9, 8, 8]\n"
     ]
    }
   ],
   "source": [
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "946a19de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5, 8, 6, 3, 4, 9, 4, 0, 8, 4, 8, 4, 6, 5, 9, 1, 6, 4, 9, 3, 0,\n",
       "       3, 3, 4, 6, 4, 6, 4, 1, 1, 5, 8, 7, 6, 1, 8, 6, 4, 3, 6, 4, 9, 5,\n",
       "       1, 4, 6, 9, 8, 8])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f310e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[181. 178. 189.]\n",
      "  [180. 177. 188.]\n",
      "  [179. 176. 187.]\n",
      "  ...\n",
      "  [195. 190. 197.]\n",
      "  [186. 181. 188.]\n",
      "  [202. 197. 204.]]\n",
      "\n",
      " [[176. 173. 184.]\n",
      "  [176. 173. 184.]\n",
      "  [176. 173. 184.]\n",
      "  ...\n",
      "  [134. 129. 136.]\n",
      "  [152. 147. 154.]\n",
      "  [150. 145. 152.]]\n",
      "\n",
      " [[177. 174. 185.]\n",
      "  [178. 175. 186.]\n",
      "  [179. 176. 187.]\n",
      "  ...\n",
      "  [194. 189. 196.]\n",
      "  [110. 105. 112.]\n",
      "  [197. 192. 199.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[149. 146. 157.]\n",
      "  [151. 148. 159.]\n",
      "  [153. 150. 161.]\n",
      "  ...\n",
      "  [134. 129. 136.]\n",
      "  [107. 102. 109.]\n",
      "  [ 89.  84.  91.]]\n",
      "\n",
      " [[145. 142. 153.]\n",
      "  [147. 144. 155.]\n",
      "  [150. 147. 158.]\n",
      "  ...\n",
      "  [152. 147. 154.]\n",
      "  [148. 143. 150.]\n",
      "  [120. 115. 122.]]\n",
      "\n",
      " [[150. 147. 158.]\n",
      "  [148. 145. 156.]\n",
      "  [148. 145. 156.]\n",
      "  ...\n",
      "  [121. 116. 123.]\n",
      "  [108. 103. 110.]\n",
      "  [144. 139. 146.]]]\n"
     ]
    }
   ],
   "source": [
    "for images_batch,labels_batch in test.take(1):\n",
    "    first_img = np.array(images_batch[0],dtype=\"float32\")\n",
    "    first_label = labels_batch[0].numpy()\n",
    "print(first_img)\n",
    "arr=[first_img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7173514",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.allocate_tensors()\n",
    "interpreter.set_tensor(input_details[0]['index'],arr)\n",
    "interpreter.invoke()\n",
    "batch_prediction=interpreter.get_tensor(output_details[0]['index'])\n",
    "label1 = np.argmax(batch_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae7cf0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 8\n"
     ]
    }
   ],
   "source": [
    "print(first_label,label1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85637424",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
